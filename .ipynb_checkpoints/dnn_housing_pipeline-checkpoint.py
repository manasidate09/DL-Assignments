{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cfb68-e124-4413-b3d1-5dd4e0f06ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# === Pipeline Functions ===\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = shuffle(df, random_state=42)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.dropna(subset=[\"SalePrice\"])\n",
    "    X = df.drop(columns=[\"SalePrice\", \"Order\", \"PID\"], errors='ignore')\n",
    "    y = df[\"SalePrice\"].values.reshape(-1, 1)\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "    return X_processed, y_scaled, preprocessor, y_scaler\n",
    "\n",
    "def split_data(X, y, test_size=0.2):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)  # Linear output for regression\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# === Main Execution ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and process data\n",
    "    path = \"AmesHousing.csv\"  # Update this if the file path is different\n",
    "    df = load_data(path)\n",
    "    X, y, preprocessor, y_scaler = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_model(X_train.shape[1])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test MAE: {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f7c9e-c5cd-4b31-9b96-08b8212ac988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
